/**
 * è¯·æ±‚Dumpå·¥å…·
 * ç”¨äºè®°å½•Claude APIè¯·æ±‚çš„åŸå§‹å’Œæœ€ç»ˆç‰ˆæœ¬
 */

const fs = require('fs').promises
const path = require('path')
const logger = require('./logger')

class RequestDumper {
  constructor() {
    this.dumpsBasePath = path.join(process.cwd(), 'logs', 'dumps')
  }

  /**
   * æ£€æŸ¥æ˜¯å¦åº”è¯¥å¯ç”¨dump
   * @returns {boolean} æ˜¯å¦åº”è¯¥dump
   */
  shouldDump() {
    // è·å–å½“å‰æ—¥å¿—çº§åˆ«
    const currentLevel = logger.level
    
    // Winstonæ—¥å¿—çº§åˆ«æ•°å€¼æ˜ å°„
    const levelValues = {
      error: 0,
      warn: 1,
      info: 2,
      http: 3,
      verbose: 4,
      debug: 5,
      silly: 6
    }
    
    // å½“å‰çº§åˆ«æ•°å€¼ >= info(2) æ—¶å¯ç”¨dump
    // å³ï¼šinfoã€httpã€verboseã€debugã€sillyçº§åˆ«æ—¶å¯ç”¨
    const currentLevelValue = levelValues[currentLevel] !== undefined ? levelValues[currentLevel] : 2
    return currentLevelValue >= levelValues.info
  }

  /**
   * ç¡®ä¿dumpç›®å½•å­˜åœ¨
   * @param {string} model - æ¨¡å‹åç§°
   * @returns {Promise<string>} ç›®å½•è·¯å¾„
   */
  async ensureDumpDirectory(model) {
    const modelDir = path.join(this.dumpsBasePath, model)
    try {
      await fs.mkdir(modelDir, { recursive: true })
      return modelDir
    } catch (error) {
      logger.error('âŒ Failed to create dump directory:', error)
      throw error
    }
  }

  /**
   * ç”Ÿæˆdumpæ–‡ä»¶å
   * @param {string} type - 'original' æˆ– 'final'
   * @returns {string} æ–‡ä»¶å
   */
  generateFileName(type) {
    const now = new Date()
    const year = now.getFullYear()
    const month = String(now.getMonth() + 1).padStart(2, '0')
    const day = String(now.getDate()).padStart(2, '0')
    const hours = String(now.getHours()).padStart(2, '0')
    const minutes = String(now.getMinutes()).padStart(2, '0')
    const seconds = String(now.getSeconds()).padStart(2, '0')
    const milliseconds = String(now.getMilliseconds()).padStart(3, '0')

    return `${year}${month}${day}_${hours}${minutes}${seconds}_${milliseconds}_${type}.log`
  }

  /**
   * æ ¼å¼åŒ–dumpå†…å®¹
   * @param {Object} data - dumpæ•°æ®
   * @returns {string} æ ¼å¼åŒ–çš„å†…å®¹
   */
  formatDumpContent(data) {
    const {
      type,
      model,
      timestamp,
      url,
      accountId,
      apiKey,
      sessionHash,
      headers,
      body,
      metadata = {}
    } = data

    let content = '=== REQUEST DUMP ===\n'
    content += `Timestamp: ${new Date(timestamp).toISOString()}\n`
    content += `Type: ${type.toUpperCase()}\n`
    content += `Model: ${model || 'unknown'}\n`

    if (url) {
      content += `Request URL: ${url}\n`
    }

    if (accountId) {
      content += `Account ID: ${accountId}\n`
    }

    if (apiKey) {
      const maskedKey = apiKey.key ? `${apiKey.key.substring(0, 8)}...` : 'unknown'
      content += `API Key: ${maskedKey} (name: ${apiKey.name || 'unnamed'})\n`
    }

    if (sessionHash) {
      content += `Session Hash: ${sessionHash}\n`
    }

    content += '\n=== HEADERS ===\n'
    content += JSON.stringify(this.sanitizeHeaders(headers), null, 2)

    content += '\n\n=== REQUEST BODY ===\n'
    content += JSON.stringify(body, null, 2)

    if (Object.keys(metadata).length > 0) {
      content += '\n\n=== METADATA ===\n'
      Object.entries(metadata).forEach(([key, value]) => {
        content += `${key}: ${value}\n`
      })
    }

    content += '\n=== END DUMP ===\n'

    return content
  }

  /**
   * æ¸…ç†æ•æ„Ÿheaderä¿¡æ¯
   * @param {Object} headers - åŸå§‹headers
   * @returns {Object} æ¸…ç†åçš„headers
   */
  sanitizeHeaders(headers) {
    if (!headers) {
      return {}
    }

    const sanitized = { ...headers }
    const sensitiveKeys = ['authorization', 'x-api-key', 'cookie', 'proxy-authorization']

    Object.keys(sanitized).forEach((key) => {
      const lowerKey = key.toLowerCase()
      if (sensitiveKeys.includes(lowerKey)) {
        if (lowerKey === 'authorization' && sanitized[key]) {
          // ä¿ç•™Bearerå‰ç¼€ï¼Œmask token
          if (sanitized[key].startsWith('Bearer ')) {
            sanitized[key] = 'Bearer [MASKED]'
          } else {
            sanitized[key] = '[MASKED]'
          }
        } else {
          sanitized[key] = '[MASKED]'
        }
      }
    })

    return sanitized
  }

  /**
   * DumpåŸå§‹è¯·æ±‚
   * @param {Object} params - dumpå‚æ•°
   */
  async dumpOriginalRequest(params) {
    // æ£€æŸ¥æ˜¯å¦åº”è¯¥å¯ç”¨dump
    if (!this.shouldDump()) {
      return
    }

    const { model, url, headers, body, apiKey, sessionHash } = params

    try {
      const modelName = model || body?.model || 'unknown-model'
      const dirPath = await this.ensureDumpDirectory(modelName)
      const fileName = this.generateFileName('original')
      const filePath = path.join(dirPath, fileName)

      const dumpData = {
        type: 'original',
        model: modelName,
        timestamp: Date.now(),
        url,
        apiKey,
        sessionHash,
        headers,
        body,
        metadata: {
          'Stream Mode': body?.stream ? 'true' : 'false',
          'Max Tokens': body?.max_tokens || 'not specified'
        }
      }

      const content = this.formatDumpContent(dumpData)
      await fs.writeFile(filePath, content, 'utf8')

      logger.debug(`ğŸ“ Original request dumped to: ${fileName}`)
    } catch (error) {
      logger.error('âŒ Failed to dump original request:', error)
      // ä¸æŠ›å‡ºé”™è¯¯ï¼Œé¿å…å½±å“æ­£å¸¸è¯·æ±‚å¤„ç†
    }
  }

  /**
   * Dumpæœ€ç»ˆè¯·æ±‚
   * @param {Object} params - dumpå‚æ•°
   */
  async dumpFinalRequest(params) {
    // æ£€æŸ¥æ˜¯å¦åº”è¯¥å¯ç”¨dump
    if (!this.shouldDump()) {
      return
    }

    const { model, url, headers, body, accountId, proxyInfo, sessionHash } = params

    try {
      const modelName = model || body?.model || 'unknown-model'
      const dirPath = await this.ensureDumpDirectory(modelName)
      const fileName = this.generateFileName('final')
      const filePath = path.join(dirPath, fileName)

      const metadata = {
        'Stream Mode': body?.stream ? 'true' : 'false',
        'Max Tokens': body?.max_tokens || 'not specified'
      }

      if (proxyInfo) {
        metadata['Has Proxy'] = 'true'
        metadata['Proxy Type'] = proxyInfo.type || 'unknown'
      } else {
        metadata['Has Proxy'] = 'false'
      }

      const dumpData = {
        type: 'final',
        model: modelName,
        timestamp: Date.now(),
        url,
        accountId,
        sessionHash,
        headers,
        body,
        metadata
      }

      const content = this.formatDumpContent(dumpData)
      await fs.writeFile(filePath, content, 'utf8')

      logger.debug(`ğŸ“ Final request dumped to: ${fileName}`)
    } catch (error) {
      logger.error('âŒ Failed to dump final request:', error)
      // ä¸æŠ›å‡ºé”™è¯¯ï¼Œé¿å…å½±å“æ­£å¸¸è¯·æ±‚å¤„ç†
    }
  }

  /**
   * æ¸…ç†æ—§çš„dumpæ–‡ä»¶ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰
   * @param {number} daysToKeep - ä¿ç•™å¤©æ•°
   */
  async cleanOldDumps(daysToKeep = 7) {
    try {
      const cutoffTime = Date.now() - daysToKeep * 24 * 60 * 60 * 1000
      const models = await fs.readdir(this.dumpsBasePath)

      for (const model of models) {
        const modelDir = path.join(this.dumpsBasePath, model)
        const stats = await fs.stat(modelDir)

        if (stats.isDirectory()) {
          const files = await fs.readdir(modelDir)

          for (const file of files) {
            const filePath = path.join(modelDir, file)
            const fileStats = await fs.stat(filePath)

            if (fileStats.mtime.getTime() < cutoffTime) {
              await fs.unlink(filePath)
              logger.debug(`ğŸ—‘ï¸ Deleted old dump file: ${file}`)
            }
          }
        }
      }
    } catch (error) {
      logger.error('âŒ Failed to clean old dumps:', error)
    }
  }
}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
module.exports = new RequestDumper()
